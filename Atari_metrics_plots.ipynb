{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./logs/run8\"\n",
    "DATASET = \"Atari\"\n",
    "MODEL_NAME = \"NatureDQNNetwork\"\n",
    "NUM_EXPERIENCES = 5\n",
    "valid_colors = ['green', 'red', 'cyan', 'magenta', 'black', 'purple', 'orange', 'brown', 'gray', 'olive', 'indigo', 'turquoise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all combinations of training\n",
    "run2name = {\n",
    "    # \"n_nst_npp\" : \"Naive_NoSelfTraining_NoPostProcessing\",\n",
    "    # \"n_st_npp\" : \"Naive_SelfTraining_NoPostProcessing\",\n",
    "    # \"n_nst_pp\" : \"Naive_NoSelfTraining_PostProcessing\",\n",
    "    # \"n_nst_pp_md\" : \"Naive_NoSelfTraining_PostProcessing_MixedData\",\n",
    "\n",
    "    # \"r_nst_npp\" : \"Replay_NoSelfTraining_NoPostProcessing\",\n",
    "    # \"r_st_npp\" : \"Replay_SelfTraining_NoPostProcessing\",\n",
    "    # \"r_nst_pp\" : \"Replay_NoSelfTraining_PostProcessing\",\n",
    "    # \"r_nst_pp_md\" : \"Replay_NoSelfTraining_PostProcessing_MixedData\",\n",
    "    \n",
    "    \"j_nst_npp\" : \"JointTraining_NoSelfTraining_NoPostProcessing\",\n",
    "    \"j_st_npp_1\" : \"JointTraining_SelfTraining_1.0_NoPostProcessing\",\n",
    "    \"j_st_npp_01\" : \"JointTraining_SelfTraining_0.1_NoPostProcessing\",\n",
    "    \"j_st_npp_0075\" : \"JointTraining_SelfTraining_0.075_NoPostProcessing\",\n",
    "    \"j_st_npp_005\" : \"JointTraining_SelfTraining_0.05_NoPostProcessing\",\n",
    "    \"j_st_npp_0025\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing\",\n",
    "    \"j_st_npp_001\" : \"JointTraining_SelfTraining_0.01_NoPostProcessing\",\n",
    "    \"j_st_npp_00075\" : \"JointTraining_SelfTraining_0.0075_NoPostProcessing\",\n",
    "    \"j_st_npp_0005\" : \"JointTraining_SelfTraining_0.005_NoPostProcessing\",\n",
    "    \"j_st_npp_00025\" : \"JointTraining_SelfTraining_0.0025_NoPostProcessing\",\n",
    "    \"j_st_npp\" : \"JointTraining_SelfTraining_0.001_NoPostProcessing\", # 0.001\n",
    "    # \"j_nst_pp\" : \"JointTraining_NoSelfTraining_PostProcessing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2label = {\n",
    "    \"n_nst_npp\" : \"Naive\",\n",
    "    \"n_st_npp\" : \"Naive_SelfTraining\",\n",
    "    \"n_nst_pp\" : \"Naive_PostProcessing\",\n",
    "    \"n_nst_pp_md\" : \"Naive_PostProcessing_MixedData\",\n",
    "\n",
    "    \"r_nst_npp\" : \"Replay\",\n",
    "    \"r_st_npp\" : \"Replay_SelfTraining\",\n",
    "    \"r_nst_pp\" : \"Replay_PostProcessing\",\n",
    "    \"r_nst_pp_md\" : \"Replay_PostProcessing_MixedData\",\n",
    "    \n",
    "    \"j_nst_npp\" : \"JointTraining\",\n",
    "    \"j_st_npp_1\" : \"JointTraining_ST_1\",\n",
    "    \"j_st_npp_01\" : \"JointTraining_ST_0.1\",\n",
    "    \"j_st_npp_001\" : \"JointTraining_ST_0.01\",\n",
    "    \"j_st_npp_005\" : \"JointTraining_ST_0.05\",\n",
    "    \"j_st_npp_0025\" : \"JointTraining_ST_0.025\",\n",
    "    \"j_st_npp_0075\" : \"JointTraining_ST_0.075\",\n",
    "    \"j_st_npp_0005\" : \"JointTraining_ST_0.005\",\n",
    "    \"j_st_npp_00025\" : \"JointTraining_ST_0.0025\",\n",
    "    \"j_st_npp_00075\" : \"JointTraining_ST_0.0075\",\n",
    "    \"j_st_npp\" : \"JointTraining_ST_0.001\",\n",
    "    \"j_nst_pp\" : \"JointTraining_PostProcessing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_accuracy = []\n",
    "running_ece = []\n",
    "final_accuracy = []\n",
    "final_ece = []\n",
    "bins = None\n",
    "ece_hist_vals = []\n",
    "\n",
    "for k, name in run2name.items():\n",
    "    print(f\">> {name} <<\")\n",
    "    with open(f\"{DATA_PATH}/{DATASET}_{MODEL_NAME}_{name}_dict\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "        # print(\"\\n---- ACCURACY ----\")\n",
    "\n",
    "        metric_str = \"Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp\"\n",
    "        m = []\n",
    "        for i in range(len(data)):\n",
    "            cur_exp_dict = data[i]\n",
    "            cur_exp_acc = 0\n",
    "            # compute the average over the experiences trained so far (i)\n",
    "            for j in range(i+1):\n",
    "                # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "                cur_exp_acc += cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            m.append(cur_exp_acc/(i+1))\n",
    "        \n",
    "        # duplicate for JointTraining\n",
    "        if len(m) < NUM_EXPERIENCES:\n",
    "            m = m*NUM_EXPERIENCES\n",
    "        running_accuracy.append((k, m))\n",
    "        final_accuracy.append((k, running_accuracy[-1][-1][-1]))\n",
    "        # print(k, m, running_accuracy[-1][-1][-1])\n",
    "\n",
    "        # print(\"\\n---- ECE ----\")\n",
    "\n",
    "        metric_str = \"ECE_Exp/eval_phase/test_stream/Task000/Exp\"\n",
    "        m = []\n",
    "        for i in range(len(data)):\n",
    "            cur_exp_dict = data[i]\n",
    "            cur_exp_ece = 0\n",
    "            # compute the average over the experiences trained so far (i)\n",
    "            for j in range(i+1):\n",
    "                # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "                cur_exp_ece += cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            m.append(cur_exp_ece/(i+1))\n",
    "        \n",
    "        # duplicate for JointTraining\n",
    "        if len(m) < NUM_EXPERIENCES:\n",
    "            m = m*NUM_EXPERIENCES\n",
    "        running_ece.append((k, m))\n",
    "        final_ece.append((k, running_ece[-1][-1][-1]))\n",
    "        # print(k, m, running_ece[-1][-1][-1])\n",
    "\n",
    "        # print(\"\\n---- ECE HISTOGRAMS ----\")\n",
    "\n",
    "        metric_str = \"ExpECEHistogram/eval_phase/test_stream/Exp\"\n",
    "        m = []\n",
    "        i = -1 # after last experience\n",
    "        cur_exp_dict = data[i]\n",
    "        for j in range(NUM_EXPERIENCES):\n",
    "            # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "            fig = cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            axes_list = fig.get_axes()\n",
    "            for ax in axes_list:\n",
    "                for line in ax.get_lines()[-1:]:\n",
    "                    x_data = line.get_xdata()\n",
    "                    y_data = line.get_ydata()\n",
    "                    # print({'x': x_data, 'y': y_data})\n",
    "                    if bins is None:\n",
    "                        bins = x_data\n",
    "                    m.append(y_data)\n",
    "        # print(bins, m)\n",
    "        bin_vals = []\n",
    "        for i in range(len(bins)):\n",
    "            x = []\n",
    "            for j in range(len(m)):\n",
    "                # print(j, i, m[j][i])\n",
    "                x.append(m[j][i])\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            bin_vals.append((mean, std))\n",
    "        # print(k, bin_vals)\n",
    "        ece_hist_vals.append((k, bin_vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 1: Average accuracy on all experiences after training on exp j\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "x_axis = list(range(1, NUM_EXPERIENCES+1))\n",
    "for i, (name, vals) in enumerate(running_accuracy):\n",
    "    plt.plot(x_axis, vals, label=run2label[name], color=valid_colors[i])\n",
    "plt.title('Average Experience Accuracy')\n",
    "plt.xlabel('#Trained Experience')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(1, NUM_EXPERIENCES)\n",
    "plt.xticks(x_axis, x_axis)\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.savefig(f'./imgs/{DATASET}_{NUM_EXPERIENCES}_{str.lower(\"Average_Experience_Accuracy\")}.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 2: Average ece on all experiences after training on exp j\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "x_axis = list(range(1, NUM_EXPERIENCES+1))\n",
    "for i, (name, vals) in enumerate(running_ece):\n",
    "    plt.plot(x_axis, vals, label=run2label[name], color=valid_colors[i])\n",
    "plt.title('Average Experience ECE')\n",
    "plt.xlabel('#Trained Experience')\n",
    "plt.ylabel('ECE')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(1, NUM_EXPERIENCES)\n",
    "plt.xticks(x_axis, x_axis)\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.savefig(f'./imgs/{DATASET}_{NUM_EXPERIENCES}_{str.lower(\"Average_Experience_ECE\")}.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE : average accuracy/ece on all experiences at the end of training\n",
    "\n",
    "table_data = []\n",
    "for (n, acc), (_, ece) in zip(final_accuracy, final_ece):\n",
    "    table_data.append((run2label[n], round(acc, 2), round(ece, 4)))\n",
    "\n",
    "dt = pd.DataFrame(table_data, columns=[\"RunName\", \"Accuracy\", \"ECE\"])\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt.to_latex(index=False, float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM : avg/std across all experiences at the end of training\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(12, 8))\n",
    "axs = axs.flatten()\n",
    "for i, (name, vals) in enumerate(ece_hist_vals):\n",
    "    m = [e[0] for e in vals]\n",
    "    s = [e[1] for e in vals]\n",
    "    l = [max(e[0] - e[1], 0) for e in vals] # cap lower-bound at zero\n",
    "    u = [e[0] + e[1] for e in vals]\n",
    "    axs[i].plot([0, 1], [0, 1], '--', label='ideal')\n",
    "    # axs[i].plot(bins, m, color=valid_colors[i])\n",
    "    # axs[i].fill_between(bins, l, u, alpha=0.3, linestyle='--', color=valid_colors[i])\n",
    "    axs[i].errorbar(bins, m, yerr=s, marker=\"o\", linestyle=\"--\", capsize=3, capthick=1, color=valid_colors[i])\n",
    "    axs[i].set_ylim(-0.05, 1)\n",
    "    axs[i].set_xlim(0, 1)\n",
    "    axs[i].set_ylabel(\"Accuracy\")\n",
    "    axs[i].set_xlabel(\"Confidence\")\n",
    "    # axs[i].legend(loc='upper left', fontsize='small')\n",
    "    axs[i].set_title(run2label[name])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./imgs/{DATASET}_{NUM_EXPERIENCES}_avg_std_calibration.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "plt.plot([0, 1], [0, 1], '--', label='ideal')\n",
    "for i, (name, vals) in enumerate(ece_hist_vals):\n",
    "    m = [e[0] for e in vals]\n",
    "    s = [e[1] for e in vals]\n",
    "    plt.errorbar(bins, m, yerr=s, marker=\"o\", linestyle=\"--\", capsize=3, capthick=1, color=valid_colors[i], label=run2label[name])\n",
    "plt.legend(loc='best', fontsize='small')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
