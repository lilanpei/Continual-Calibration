diff --git a/ModelDecorator.py b/ModelDecorator.py
index d2b3ec6..cf06dcf 100644
--- a/ModelDecorator.py
+++ b/ModelDecorator.py
@@ -6,6 +6,7 @@ Adapted from: https://github.com/gpleiss/temperature_scaling
 import torch as th
 from torch import nn, optim
 from ECE_metrics import ECE
+from _ECELoss import _ECELoss
 from avalanche.benchmarks.utils.data_loader import TaskBalancedDataLoader
 
 class ModelWithTemperature(nn.Module):
@@ -48,6 +49,7 @@ class ModelWithTemperature(nn.Module):
         logits_list = []
         labels_list = []
         nll_criterion = nn.CrossEntropyLoss().to(self.device)
+        ece_criterion = _ECELoss().to(self.device)
         ece_metric = ECE()
         with th.no_grad():
             for input, label, _ in TaskBalancedDataLoader(experience_val):
@@ -59,9 +61,10 @@ class ModelWithTemperature(nn.Module):
 
         # Calculate NLL and ECE before temperature scaling
         before_temperature_nll = nll_criterion(logits, labels).item()
+        before_temperature_ece = ece_criterion(logits, labels).item()
         ece_metric.update(logits, labels)
         before_temperature_ece_metric = ece_metric.result()
-        print('##### Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece_metric))
+        print('##### Before temperature - NLL: %.3f, ECE: %.3f, ECE_metric: %.3f' % (before_temperature_nll, before_temperature_ece, before_temperature_ece_metric))
         ece_metric.reset()
 
         def eval():
@@ -73,10 +76,11 @@ class ModelWithTemperature(nn.Module):
 
         # Calculate NLL and ECE after temperature scaling
         after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()
+        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()
         ece_metric.update(self.temperature_scale(logits), labels)
         after_temperature_ece_metric = ece_metric.result()
         print('##### Optimal temperature: %.3f' % self.temperature.data)
-        print('##### After temperature - NLL: %.3f, ECE: %.3f' % (after_temperature_nll, after_temperature_ece_metric))
+        print('##### After temperature - NLL: %.3f, ECE: %.3f, ECE_metric: %.3f' % (after_temperature_nll, after_temperature_ece, after_temperature_ece_metric))
         ece_metric.reset()
 
         return self
@@ -108,6 +112,7 @@ class MatrixAndVectorScaling(nn.Module):
         logits_list = []
         labels_list = []
         nll_criterion = nn.CrossEntropyLoss().to(self.device)
+        ece_criterion = _ECELoss().to(self.device)
         ece_metric = ECE()
         with th.no_grad():
             for input, label, _ in TaskBalancedDataLoader(experience_val):
@@ -119,9 +124,10 @@ class MatrixAndVectorScaling(nn.Module):
 
         # Calculate NLL and ECE before scaling
         before_calibration_nll = nll_criterion(logits, labels).item()
+        before_calibration_ece = ece_criterion(logits, labels).item()
         ece_metric.update(logits, labels)
         before_calibration_ece_metric = ece_metric.result()
-        print('##### Before calibration - NLL: %.3f, ECE: %.3f' % (before_calibration_nll, before_calibration_ece_metric))
+        print('##### Before calibration - NLL: %.3f, ECE: %.3f, ECE_metric: %.3f' % (before_calibration_nll, before_calibration_ece, before_calibration_ece_metric))
         ece_metric.reset()
 
         def eval():
@@ -133,9 +139,10 @@ class MatrixAndVectorScaling(nn.Module):
 
         # Calculate NLL and ECE after scaling
         after_calibration_nll = nll_criterion(self.forward(logits), labels).item()
+        after_calibration_ece = ece_criterion(self.forward(logits), labels).item()
         ece_metric.update(self.forward(logits), labels)
         after_calibration_ece_metric = ece_metric.result()
-        print('##### After calibration - NLL: %.3f, ECE: %.3f' % (after_calibration_nll, after_calibration_ece_metric))
+        print('##### After calibration - NLL: %.3f, ECE: %.3f, ECE_metric: %.3f' % (after_calibration_nll, after_calibration_ece, after_calibration_ece_metric))
         ece_metric.reset()
 
         return self
diff --git a/_ECELoss.py b/_ECELoss.py
new file mode 100755
index 0000000..5ea30cc
--- /dev/null
+++ b/_ECELoss.py
@@ -0,0 +1,48 @@
+import torch
+from torch import nn
+from torch.nn import functional as F
+
+class _ECELoss(nn.Module):
+    """
+    Calculates the Expected Calibration Error of a model.
+    (This isn't necessary for temperature scaling, just a cool metric).
+
+    The input to this loss is the logits of a model, NOT the softmax scores.
+
+    This divides the confidence outputs into equally-sized interval bins.
+    In each bin, we compute the confidence gap:
+
+    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |
+
+    We then return a weighted average of the gaps, based on the number
+    of samples in each bin
+
+    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.
+    "Obtaining Well Calibrated Probabilities Using Bayesian Binning." AAAI.
+    2015.
+    """
+    def __init__(self, n_bins=10):
+        """
+        n_bins (int): number of confidence interval bins
+        """
+        super(_ECELoss, self).__init__()
+        bin_boundaries = torch.linspace(0, 1, n_bins + 1)
+        self.bin_lowers = bin_boundaries[:-1]
+        self.bin_uppers = bin_boundaries[1:]
+
+    def forward(self, logits, labels):
+        softmaxes = F.softmax(logits, dim=1)
+        confidences, predictions = torch.max(softmaxes, 1)
+        accuracies = predictions.eq(labels)
+
+        ece = torch.zeros(1, device=logits.device)
+        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):
+            # Calculated |confidence - accuracy| in each bin
+            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())
+            prop_in_bin = in_bin.float().mean()
+            if prop_in_bin.item() > 0:
+                accuracy_in_bin = accuracies[in_bin].float().mean()
+                avg_confidence_in_bin = confidences[in_bin].mean()
+                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin
+
+        return ece
\ No newline at end of file
