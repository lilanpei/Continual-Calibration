{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXPERIENCES = 10\n",
    "# DATA_PATH = f\"./logs/ST_SplitCIFAR100_{NUM_EXPERIENCES}\"\n",
    "# DATA_PATH = f\"./logs/F_SplitCIFAR100_2\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_lwf\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_DER_500\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_DER_2000\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_DER_500_2\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_DER_2000_2\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_DER_RESNET\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_D_ST\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_D_HP\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_CHECK\"\n",
    "\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_J\"\n",
    "DATA_PATH = f\"./logs/SplitCIFAR100_D\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_R\"\n",
    "# DATA_PATH = f\"./logs/SplitCIFAR100_N\"\n",
    "\n",
    "DATASET = \"SplitCIFAR100\"\n",
    "# MODEL_NAME = \"ResNet18\"\n",
    "MODEL_NAME = \"ResNet110\"\n",
    "valid_colors = ['green', 'red', 'cyan', 'magenta', 'black', 'purple', 'orange', 'brown', 'gray', 'olive', 'indigo', 'turquoise', 'green', 'red', 'cyan', 'magenta']*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all combinations of training\n",
    "run2name = {    \n",
    "    # \"j_nst_npp\" : \"JointTraining_NoSelfTraining_NoPostProcessing\",\n",
    "    # # \"j_st_npp_1\" : \"JointTraining_SelfTraining1.0_NoPostProcessing\",\n",
    "    # \"j_st_npp_01\" : \"JointTraining_SelfTraining_0.1_NoPostProcessing\", #\n",
    "    # # \"j_st_npp_0075\" : \"JointTraining_SelfTraining0.075_NoPostProcessing\",\n",
    "    # \"j_st_npp_005\" : \"JointTraining_SelfTraining_0.05_NoPostProcessing\", #\n",
    "    # \"j_st_npp_0025\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing\", #\n",
    "    # # \"j_st_npp_001\" : \"JointTraining_SelfTraining0.01_NoPostProcessing\",\n",
    "    # # \"j_st_npp_00075\" : \"JointTraining_SelfTraining0.0075_NoPostProcessing\",\n",
    "    # # \"j_st_npp_0005\" : \"JointTraining_SelfTraining0.005_NoPostProcessing\",\n",
    "    # # \"j_st_npp_00025\" : \"JointTraining_SelfTraining0.0025_NoPostProcessing\",\n",
    "    # # \"j_st_npp\" : \"JointTraining_SelfTraining_NoPostProcessing\", # 0.001\n",
    "    # # \"j_nst_pp\" : \"JointTraining_NoSelfTraining_PostProcessing\"\n",
    "\n",
    "    # \"j_nst_npp_v1\" : \"JointTraining_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"j_nst_npp_v2\" : \"JointTraining_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"j_nst_npp_v3\" : \"JointTraining_NoSelfTraining_NoPostProcessing3\",\n",
    "    # \"j_st_npp_0025_v1\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing1\",\n",
    "    # \"j_st_npp_0025_v2\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing2\",\n",
    "    # \"j_st_npp_0025_v3\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing3\",\n",
    "\n",
    "    # \"j_nst_npp_v1\" : \"JointTraining_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"j_nst_npp_v2\" : \"JointTraining_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"j_nst_npp_v3\" : \"JointTraining_NoSelfTraining_NoPostProcessing3\",\n",
    "\n",
    "    # \"r_nst_npp_v1\" : \"Replay_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"r_nst_npp_v2\" : \"Replay_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"r_nst_npp_v3\" : \"Replay_NoSelfTraining_NoPostProcessing3\",\n",
    "\n",
    "    # \"n_nst_npp_v1\" : \"Naive_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"n_nst_npp_v2\" : \"Naive_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"n_nst_npp_v3\" : \"Naive_NoSelfTraining_NoPostProcessing3\",\n",
    "\n",
    "    # \"d_nst_npp_hp1\" : \"DER_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"d_nst_npp_hp2\" : \"DER_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"d_nst_npp_hp3\" : \"DER_NoSelfTraining_NoPostProcessing3\",\n",
    "    # \"d_nst_npp_hp4\" : \"DER_NoSelfTraining_NoPostProcessing4\",\n",
    "    # \"d_nst_npp_hp5\" : \"DER_NoSelfTraining_NoPostProcessing5\",\n",
    "    # \"d_nst_npp_hp6\" : \"DER_NoSelfTraining_NoPostProcessing6\",\n",
    "    # \"d_nst_npp_hp7\" : \"DER_NoSelfTraining_NoPostProcessing7\",\n",
    "    # \"d_nst_npp_hp8\" : \"DER_NoSelfTraining_NoPostProcessing8\",\n",
    "    # \"d_nst_npp_hp9\" : \"DER_NoSelfTraining_NoPostProcessing9\",\n",
    "    # \"d_nst_npp_hp10\" : \"DER_NoSelfTraining_NoPostProcessing10\",\n",
    "    # \"d_nst_npp_hp11\" : \"DER_NoSelfTraining_NoPostProcessing11\",\n",
    "    # \"d_nst_npp_hp12\" : \"DER_NoSelfTraining_NoPostProcessing12\",\n",
    "    # \"d_nst_npp_hp13\" : \"DER_NoSelfTraining_NoPostProcessing13\",\n",
    "    # \"d_nst_npp_hp14\" : \"DER_NoSelfTraining_NoPostProcessing14\",\n",
    "\n",
    "    # \"d_nst_npp_m1\" : \"DER_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"d_nst_npp_m2\" : \"DER_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"d_nst_npp_m3\" : \"DER_NoSelfTraining_NoPostProcessing3\",\n",
    "    # \"d_nst_npp_m4\" : \"DER_NoSelfTraining_NoPostProcessing4\",\n",
    "    # \"d_nst_npp_m5\" : \"DER_NoSelfTraining_NoPostProcessing5\",\n",
    "    # \"d_nst_npp_m6\" : \"DER_NoSelfTraining_NoPostProcessing6\",\n",
    "    # \"d_nst_npp_m7\" : \"DER_NoSelfTraining_NoPostProcessing7\",\n",
    "    # \"d_nst_npp_m8\" : \"DER_NoSelfTraining_NoPostProcessing8\",\n",
    "    # \"d_nst_npp_m9\" : \"DER_NoSelfTraining_NoPostProcessing9\",\n",
    "    # \"d_nst_npp_m10\" : \"DER_NoSelfTraining_NoPostProcessing10\",\n",
    "\n",
    "    # \"d_nst_npp_v1\" : \"DER_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"d_nst_npp_v2\" : \"DER_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"d_nst_npp_v3\" : \"DER_NoSelfTraining_NoPostProcessing3\",\n",
    "\n",
    "    # \"d_st_npp_01\" : \"DER_SelfTraining_0.1_NoPostProcessing1\",\n",
    "    # \"d_st_npp_0075\" : \"DER_SelfTraining_0.075_NoPostProcessing1\",\n",
    "    # \"d_st_npp_005\" : \"DER_SelfTraining_0.05_NoPostProcessing1\",\n",
    "    # \"d_st_npp_0025_v1\" : \"DER_SelfTraining_0.025_NoPostProcessing1\",\n",
    "    # \"d_st_npp_001\" : \"DER_SelfTraining_0.01_NoPostProcessing1\",\n",
    "    # \"d_st_npp_00075\" : \"DER_SelfTraining_0.0075_NoPostProcessing1\",\n",
    "    # \"d_st_npp_0005\" : \"DER_SelfTraining_0.005_NoPostProcessing1\",\n",
    "    # \"d_st_npp_00025\" : \"DER_SelfTraining_0.0025_NoPostProcessing1\",\n",
    "\n",
    "    # \"d_nst_npp_v1\" : \"DER_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"d_nst_npp_v2\" : \"DER_NoSelfTraining_NoPostProcessing2\",\n",
    "    # \"d_nst_npp_v3\" : \"DER_NoSelfTraining_NoPostProcessing3\",\n",
    "    # \"d_nst_npp_v4\" : \"DER_NoSelfTraining_NoPostProcessing4\",\n",
    "    # \"d_nst_npp_v5\" : \"DER_NoSelfTraining_NoPostProcessing5\",\n",
    "    # \"d_nst_npp_v6\" : \"DER_NoSelfTraining_NoPostProcessing6\",\n",
    "    # \"d_nst_npp_v7\" : \"DER_NoSelfTraining_NoPostProcessing7\",\n",
    "    # \"d_nst_npp_v8\" : \"DER_NoSelfTraining_NoPostProcessing8\",\n",
    "    # \"d_nst_npp_v9\" : \"DER_NoSelfTraining_NoPostProcessing9\",\n",
    "    # \"d_nst_npp_v10\" : \"DER_NoSelfTraining_NoPostProcessing10\",\n",
    "    # \"d_nst_npp_v11\" : \"DER_NoSelfTraining_NoPostProcessing11\",\n",
    "    # \"d_nst_npp_v12\" : \"DER_NoSelfTraining_NoPostProcessing12\",\n",
    "    # \"d_nst_npp_v13\" : \"DER_NoSelfTraining_NoPostProcessing13\",\n",
    "    # \"d_nst_npp_v14\" : \"DER_NoSelfTraining_NoPostProcessing14\",\n",
    "    # \"d_nst_npp_v15\" : \"DER_NoSelfTraining_NoPostProcessing15\",\n",
    "    # \"d_nst_npp_v16\" : \"DER_NoSelfTraining_NoPostProcessing16\",\n",
    "    # \"d_nst_npp_v17\" : \"DER_NoSelfTraining_NoPostProcessing17\",\n",
    "    # \"d_nst_npp_v18\" : \"DER_NoSelfTraining_NoPostProcessing18\",\n",
    "    # \"d_nst_npp_v19\" : \"DER_NoSelfTraining_NoPostProcessing19\",\n",
    "    # \"d_nst_npp_v20\" : \"DER_NoSelfTraining_NoPostProcessing20\",\n",
    "    # \"d_nst_npp_v21\" : \"DER_NoSelfTraining_NoPostProcessing21\",\n",
    "    # \"d_nst_npp_v22\" : \"DER_NoSelfTraining_NoPostProcessing22\",\n",
    "    # \"d_nst_npp_v23\" : \"DER_NoSelfTraining_NoPostProcessing23\",\n",
    "    # \"d_nst_npp_v24\" : \"DER_NoSelfTraining_NoPostProcessing24\",\n",
    "\n",
    "    # \"j_nst_npp_v1\" : \"JointTraining_NoSelfTraining_NoPostProcessing1\",\n",
    "    # \"j_nst_npp_v2\" : \"JointTraining_NoSelfTraining_NoPostProcessing0\",\n",
    "    # \"j_st_npp_0025_v1\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing1\",\n",
    "    # \"j_st_npp_0025_v2\" : \"JointTraining_SelfTraining_0.025_NoPostProcessing0\",\n",
    "    # \"j_nst_pp_ts_v1\" : \"JointTraining_NoSelfTraining_PostProcessing_TemperatureScaling1\",\n",
    "    # \"j_nst_pp_ts_v2\" : \"JointTraining_NoSelfTraining_PostProcessing_TemperatureScaling0\",\n",
    "    # \"j_nst_pp_vs_v1\" : \"JointTraining_NoSelfTraining_PostProcessing_VectorScaling1\",\n",
    "    # \"j_nst_pp_vs_v2\" : \"JointTraining_NoSelfTraining_PostProcessing_VectorScaling0\",\n",
    "    # \"j_nst_pp_ms_v1\" : \"JointTraining_NoSelfTraining_PostProcessing_MatrixScaling1\",\n",
    "    # \"j_nst_pp_ms_v2\" : \"JointTraining_NoSelfTraining_PostProcessing_MatrixScaling0\",\n",
    "\n",
    "    \"d_nst_npp_v1\" : \"DER_NoSelfTraining_NoPostProcessing1\",\n",
    "    \"d_nst_npp_v2\" : \"DER_NoSelfTraining_NoPostProcessing0\",\n",
    "    \"d_st_npp_0025_v1\" : \"DER_SelfTraining_0.025_NoPostProcessing1\",\n",
    "    \"d_st_npp_0025_v2\" : \"DER_SelfTraining_0.025_NoPostProcessing0\",\n",
    "    \"d_nst_pp_ts_v1\" : \"DER_NoSelfTraining_PostProcessing_TemperatureScaling1\",\n",
    "    \"d_nst_pp_ts_v2\" : \"DER_NoSelfTraining_PostProcessing_TemperatureScaling0\",\n",
    "    # \"d_nst_pp_vs_v1\" : \"DER_NoSelfTraining_PostProcessing_VectorScaling1\",\n",
    "    # \"d_nst_pp_vs_v2\" : \"DER_NoSelfTraining_PostProcessing_VectorScaling0\",\n",
    "    # \"d_nst_pp_ms_v1\" : \"DER_NoSelfTraining_PostProcessing_MatrixScaling1\",\n",
    "    # \"d_nst_pp_ms_v2\" : \"DER_NoSelfTraining_PostProcessing_MatrixScaling0\",\n",
    "    \"d_nst_pp_ts_md_v1\" : \"DER_NoSelfTraining_PostProcessing_TemperatureScaling_MixedData1\",\n",
    "    \"d_nst_pp_ts_md_v2\" : \"DER_NoSelfTraining_PostProcessing_TemperatureScaling_MixedData0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2label = {\n",
    "    # \"j_nst_npp\" : \"JointTraining\",\n",
    "    # \"j_st_npp_1\" : \"JointTraining_ST_1\",\n",
    "    # \"j_st_npp_01\" : \"JointTraining_ST_0.1\",\n",
    "    # \"j_st_npp_001\" : \"JointTraining_ST_0.01\",\n",
    "    # \"j_st_npp_005\" : \"JointTraining_ST_0.05\",\n",
    "    # \"j_st_npp_0025\" : \"JointTraining_ST_0.025\",\n",
    "    # \"j_st_npp_0075\" : \"JointTraining_ST_0.075\",\n",
    "    # \"j_st_npp_0005\" : \"JointTraining_ST_0.005\",\n",
    "    # \"j_st_npp_00025\" : \"JointTraining_ST_0.0025\",\n",
    "    # \"j_st_npp_00075\" : \"JointTraining_ST_0.0075\",\n",
    "    # \"j_st_npp\" : \"JointTraining_ST_0.001\",\n",
    "    # \"j_nst_pp\" : \"JointTraining_PostProcessing\",\n",
    "\n",
    "    # \"j_nst_npp_v1\" : \"JointTraining\",\n",
    "    # \"j_nst_npp_v2\" : \"JointTraining\",\n",
    "    # \"j_nst_npp_v3\" : \"JointTraining\",\n",
    "    # \"j_st_npp_0025_v1\" : \"JointTraining_ST_0.025\",\n",
    "    # \"j_st_npp_0025_v2\" : \"JointTraining_ST_0.025\",\n",
    "    # \"j_st_npp_0025_v3\" : \"JointTraining_ST_0.025\",\n",
    "\n",
    "    # \"r_nst_npp_v1\" : \"Replay\",\n",
    "    # \"r_nst_npp_v2\" : \"Replay\",\n",
    "    # \"r_nst_npp_v3\" : \"Replay\",\n",
    "\n",
    "    # \"n_nst_npp_v1\" : \"Naive\",\n",
    "    # \"n_nst_npp_v2\" : \"Naive\",\n",
    "    # \"n_nst_npp_v3\" : \"Naive\",\n",
    "\n",
    "    # # \"d_nst_npp_v1\" : \"DER\",\n",
    "    # # \"d_nst_npp_v2\" : \"DER\",\n",
    "    # # \"d_nst_npp_v3\" : \"DER\",\n",
    "\n",
    "    # \"d_nst_npp\" : \"DER\",\n",
    "    # \"d_st_npp_01\" : \"DER_0.1\",\n",
    "    # \"d_st_npp_0075\" : \"DER_0.075\",\n",
    "    # \"d_st_npp_005\" : \"DER_0.05\",\n",
    "    # \"d_st_npp_0025_v1\" : \"DER_0.025\",\n",
    "    # \"d_st_npp_0025_v2\" : \"DER_0.025\",\n",
    "    # \"d_st_npp_0025_v3\" : \"DER_0.025\",\n",
    "    # \"d_st_npp_001\" : \"DER_0.01\",\n",
    "    # \"d_st_npp_00075\" : \"DER_0.0075\",\n",
    "    # \"d_st_npp_0005\" : \"DER_0.005\",\n",
    "    # \"d_st_npp_00025\" : \"DER_0.0025\",\n",
    "\n",
    "    # \"d_nst_npp_hp1\" : \"DER_001_01_05\",\n",
    "    # \"d_nst_npp_hp2\" : \"DER_001_01_05\",\n",
    "    # \"d_nst_npp_hp3\" : \"DER_003_01_05\",\n",
    "    # \"d_nst_npp_hp4\" : \"DER_003_01_05\",\n",
    "    # \"d_nst_npp_hp13\" : \"DER_001_01_1\",\n",
    "    # \"d_nst_npp_hp14\" : \"DER_001_01_1\",\n",
    "    # \"d_nst_npp_hp5\" : \"DER_001_02_05\",\n",
    "    # \"d_nst_npp_hp6\" : \"DER_001_02_05\",\n",
    "    # \"d_nst_npp_hp7\" : \"DER_001_02_1\",\n",
    "    # \"d_nst_npp_hp8\" : \"DER_001_02_1\",\n",
    "    # \"d_nst_npp_hp9\" : \"DER_001_05_05\",\n",
    "    # \"d_nst_npp_hp10\" : \"DER_001_05_05\",\n",
    "    # \"d_nst_npp_hp11\" : \"DER_001_05_1\",\n",
    "    # \"d_nst_npp_hp12\" : \"DER_001_05_1\",\n",
    "\n",
    "    # \"d_nst_npp_m1\" : \"DER_001_01_05\",\n",
    "    # \"d_nst_npp_m2\" : \"DER_001_01_05_500\",\n",
    "    # \"d_nst_npp_m3\" : \"DER_001_01_05_1000\",\n",
    "    # \"d_nst_npp_m4\" : \"DER_001_01_05_2000\",\n",
    "    # \"d_nst_npp_m5\" : \"DER_001_01_05_4000\",\n",
    "    # \"d_nst_npp_m6\" : \"DER_001_02_05\",\n",
    "    # \"d_nst_npp_m7\" : \"DER_001_02_05_500\",\n",
    "    # \"d_nst_npp_m8\" : \"DER_001_02_05_1000\",\n",
    "    # \"d_nst_npp_m9\" : \"DER_001_02_05_2000\",\n",
    "    # \"d_nst_npp_m10\" : \"DER_001_02_05_4000\",\n",
    "\n",
    "    # \"d_nst_npp_v1\" : \"DER_01_05\",\n",
    "    # \"d_nst_npp_v2\" : \"DER_01_05\",\n",
    "    # \"d_nst_npp_v3\" : \"DER_01_05\",\n",
    "    # \"d_nst_npp_v4\" : \"DER_01_08\",\n",
    "    # \"d_nst_npp_v5\" : \"DER_01_08\",\n",
    "    # \"d_nst_npp_v6\" : \"DER_01_08\",\n",
    "    # \"d_nst_npp_v7\" : \"DER_02_05\",\n",
    "    # \"d_nst_npp_v8\" : \"DER_02_05\",\n",
    "    # \"d_nst_npp_v9\" : \"DER_02_05\",\n",
    "    # \"d_nst_npp_v10\" : \"DER_02_08\",\n",
    "    # \"d_nst_npp_v11\" : \"DER_02_08\",\n",
    "    # \"d_nst_npp_v12\" : \"DER_02_08\",\n",
    "    # \"d_nst_npp_v13\" : \"DER_03_05\",\n",
    "    # \"d_nst_npp_v14\" : \"DER_03_05\",\n",
    "    # \"d_nst_npp_v15\" : \"DER_03_05\",\n",
    "    # \"d_nst_npp_v16\" : \"DER_03_08\",\n",
    "    # \"d_nst_npp_v17\" : \"DER_03_08\",\n",
    "    # \"d_nst_npp_v18\" : \"DER_03_08\",\n",
    "    # \"d_nst_npp_v19\" : \"DER_05_05\",\n",
    "    # \"d_nst_npp_v20\" : \"DER_05_05\",\n",
    "    # \"d_nst_npp_v21\" : \"DER_05_05\",\n",
    "    # \"d_nst_npp_v22\" : \"DER_05_08\",\n",
    "    # \"d_nst_npp_v23\" : \"DER_05_08\",\n",
    "    # \"d_nst_npp_v24\" : \"DER_05_08\",\n",
    "\n",
    "    \"j_nst_npp_v1\" : \"J\",\n",
    "    \"j_nst_npp_v2\" : \"J\",\n",
    "    \"j_st_npp_0025_v1\" : \"J + HR\",\n",
    "    \"j_st_npp_0025_v2\" : \"J + HR\",\n",
    "    \"j_nst_pp_ts_v1\" : \"J + TS\",\n",
    "    \"j_nst_pp_ts_v2\" : \"J + TS\",\n",
    "    \"j_nst_pp_vs_v1\" : \"J + VS\",\n",
    "    \"j_nst_pp_vs_v2\" : \"J + VS\",\n",
    "    \"j_nst_pp_ms_v1\" : \"J + MS\",\n",
    "    \"j_nst_pp_ms_v2\" : \"J + MS\",\n",
    "\n",
    "    \"d_nst_npp_v1\" : \"D\",\n",
    "    \"d_nst_npp_v2\" : \"D\",\n",
    "    \"d_st_npp_0025_v1\" : \"D + HR\",\n",
    "    \"d_st_npp_0025_v2\" : \"D + HR\",\n",
    "    \"d_nst_pp_ts_v1\" : \"D + TS\",\n",
    "    \"d_nst_pp_ts_v2\" : \"D + TS\",\n",
    "    # \"d_nst_pp_vs_v1\" : \"DER_NoSelfTraining_PostProcessing_VectorScaling1\",\n",
    "    # \"d_nst_pp_vs_v2\" : \"DER_NoSelfTraining_PostProcessing_VectorScaling0\",\n",
    "    # \"d_nst_pp_ms_v1\" : \"DER_NoSelfTraining_PostProcessing_MatrixScaling1\",\n",
    "    # \"d_nst_pp_ms_v2\" : \"DER_NoSelfTraining_PostProcessing_MatrixScaling0\",\n",
    "    \"d_nst_pp_ts_md_v1\" : \"D + TS + MD\",\n",
    "    \"d_nst_pp_ts_md_v2\" : \"D + TS + MD\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_accuracy = []\n",
    "running_ece = []\n",
    "final_accuracy = []\n",
    "final_ece = []\n",
    "bins = None\n",
    "ece_hist_vals = []\n",
    "\n",
    "for k, name in run2name.items():\n",
    "    print(f\">> {name} <<\")\n",
    "    with open(f\"{DATA_PATH}/{DATASET}_{MODEL_NAME}_{name}_dict\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "        # print(\"\\n---- ACCURACY ----\")\n",
    "\n",
    "        metric_str = \"Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp\"\n",
    "        m = []\n",
    "        for i in range(len(data)):\n",
    "            cur_exp_dict = data[i]\n",
    "            cur_exp_acc = 0\n",
    "            # compute the average over the experiences trained so far (i)\n",
    "            for j in range(i+1):\n",
    "                # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "                cur_exp_acc += cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            m.append(cur_exp_acc/(i+1))\n",
    "        \n",
    "        # duplicate for JointTraining\n",
    "        if len(m) < NUM_EXPERIENCES:\n",
    "            m = m*NUM_EXPERIENCES\n",
    "        running_accuracy.append((k, m))\n",
    "        final_accuracy.append((k, running_accuracy[-1][-1][-1]))\n",
    "        # print(k, m, running_accuracy[-1][-1][-1])\n",
    "\n",
    "        # print(\"\\n---- ECE ----\")\n",
    "\n",
    "        metric_str = \"ECE_Exp/eval_phase/test_stream/Task000/Exp\"\n",
    "        m = []\n",
    "        for i in range(len(data)):\n",
    "            cur_exp_dict = data[i]\n",
    "            cur_exp_ece = 0\n",
    "            # compute the average over the experiences trained so far (i)\n",
    "            for j in range(i+1):\n",
    "                # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "                cur_exp_ece += cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            # m.append(cur_exp_ece/(i+1))\n",
    "            m.append((cur_exp_ece/(i+1))*100)\n",
    "        \n",
    "        # duplicate for JointTraining\n",
    "        if len(m) < NUM_EXPERIENCES:\n",
    "            m = m*NUM_EXPERIENCES\n",
    "        running_ece.append((k, m))\n",
    "        final_ece.append((k, running_ece[-1][-1][-1]))\n",
    "        # print(k, m, running_ece[-1][-1][-1])\n",
    "\n",
    "        # print(\"\\n---- ECE HISTOGRAMS ----\")\n",
    "\n",
    "        metric_str = \"ExpECEHistogram/eval_phase/test_stream/Exp\"\n",
    "        m = []\n",
    "        i = -1 # after last experience\n",
    "        cur_exp_dict = data[i]\n",
    "        for j in range(NUM_EXPERIENCES):\n",
    "            # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "            fig = cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            axes_list = fig.get_axes()\n",
    "            for ax in axes_list:\n",
    "                for line in ax.get_lines()[-1:]:\n",
    "                    x_data = line.get_xdata()\n",
    "                    y_data = line.get_ydata()\n",
    "                    # print({'x': x_data, 'y': y_data})\n",
    "                    if bins is None:\n",
    "                        bins = x_data\n",
    "                    m.append(y_data)\n",
    "        # print(bins, m)\n",
    "        bin_vals = []\n",
    "        for i in range(len(bins)):\n",
    "            x = []\n",
    "            for j in range(len(m)):\n",
    "                # print(j, i, m[j][i])\n",
    "                x.append(m[j][i])\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            bin_vals.append((mean, std))\n",
    "        # print(k, bin_vals)\n",
    "        ece_hist_vals.append((k, bin_vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 1: Average accuracy on all experiences after training on exp j\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "x_axis = list(range(1, NUM_EXPERIENCES+1))\n",
    "for i, (name, vals) in enumerate(running_accuracy):\n",
    "    plt.plot(x_axis, vals, label=run2label[name], color=valid_colors[i])\n",
    "plt.title('Average Experience Accuracy')\n",
    "plt.xlabel('#Trained Experience')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(1, NUM_EXPERIENCES)\n",
    "plt.xticks(x_axis, x_axis)\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.savefig(f'./imgs/{DATASET}_{NUM_EXPERIENCES}_{str.lower(\"Average_Experience_Accuracy\")}.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 2: Average ece on all experiences after training on exp j\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "x_axis = list(range(1, NUM_EXPERIENCES+1))\n",
    "for i, (name, vals) in enumerate(running_ece):\n",
    "    plt.plot(x_axis, vals, label=run2label[name], color=valid_colors[i])\n",
    "plt.title('Average Experience ECE')\n",
    "plt.xlabel('#Trained Experience')\n",
    "plt.ylabel('ECE')\n",
    "# plt.ylim(0, 1)\n",
    "plt.xlim(1, NUM_EXPERIENCES)\n",
    "plt.xticks(x_axis, x_axis)\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.savefig(f'./imgs/{DATASET}_{NUM_EXPERIENCES}_{str.lower(\"Average_Experience_ECE\")}.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE : average accuracy/ece on all experiences at the end of training\n",
    "\n",
    "table_data = []\n",
    "for (n, acc), (_, ece) in zip(final_accuracy, final_ece):\n",
    "    table_data.append((run2label[n], round(acc*100, 2), round(ece, 4)))\n",
    "\n",
    "dt = pd.DataFrame(table_data, columns=[\"RunName\", \"Accuracy\", \"ECE\"])\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for each run\n",
    "mean_accuracy_per_run = dt.groupby('RunName')['Accuracy'].mean()\n",
    "std_accuracy_per_run = dt.groupby('RunName')['Accuracy'].std()\n",
    "\n",
    "mean_ece_per_run = dt.groupby('RunName')['ECE'].mean()\n",
    "std_ece_per_run = dt.groupby('RunName')['ECE'].std()\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Accuracy per Run:\\n\", mean_accuracy_per_run)\n",
    "print(\"\\nStandard Deviation of Accuracy per Run:\\n\", std_accuracy_per_run)\n",
    "\n",
    "print(\"\\nMean ECE per Run:\\n\", mean_ece_per_run)\n",
    "print(\"\\nStandard Deviation of ECE per Run:\\n\", std_ece_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt.to_latex(index=False, float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM : avg/std across all experiences at the end of training\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(12, 8))\n",
    "axs = axs.flatten()\n",
    "for i, (name, vals) in enumerate(ece_hist_vals):\n",
    "    m = [e[0] for e in vals]\n",
    "    s = [e[1] for e in vals]\n",
    "    l = [max(e[0] - e[1], 0) for e in vals] # cap lower-bound at zero\n",
    "    u = [e[0] + e[1] for e in vals]\n",
    "    axs[i].plot([0, 1], [0, 1], '--', label='ideal')\n",
    "    # axs[i].plot(bins, m, color=valid_colors[i])\n",
    "    # axs[i].fill_between(bins, l, u, alpha=0.3, linestyle='--', color=valid_colors[i])\n",
    "    axs[i].errorbar(bins, m, yerr=s, marker=\"o\", linestyle=\"--\", capsize=3, capthick=1, color=valid_colors[i])\n",
    "    axs[i].set_ylim(-0.05, 1)\n",
    "    axs[i].set_xlim(0, 1)\n",
    "    axs[i].set_ylabel(\"Accuracy\")\n",
    "    axs[i].set_xlabel(\"Confidence\")\n",
    "    # axs[i].legend(loc='upper left', fontsize='small')\n",
    "    axs[i].set_title(run2label[name])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./imgs/{DATASET}_{NUM_EXPERIENCES}_avg_std_calibration.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "plt.plot([0, 1], [0, 1], '--', label='ideal')\n",
    "for i, (name, vals) in enumerate(ece_hist_vals):\n",
    "    m = [e[0] for e in vals]\n",
    "    s = [e[1] for e in vals]\n",
    "    plt.errorbar(bins, m, yerr=s, marker=\"o\", linestyle=\"--\", capsize=3, capthick=1, color=valid_colors[i], label=run2label[name])\n",
    "plt.legend(loc='best', fontsize='small')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
