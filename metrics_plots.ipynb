{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./logs/run3\"\n",
    "DATASET = \"Atari\"\n",
    "MODEL_NAME = \"NatureDQNNetwork\"\n",
    "NUM_EXPERIENCES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all combinations of training\n",
    "run2name = {\n",
    "    \"n_nst_npp\" : \"Naive_NoSelfTraining_NoPostProcessing\",\n",
    "    \"n_st_npp\" : \"Naive_SelfTraining_NoPostProcessing\",\n",
    "    \"n_nst_pp\" : \"Naive_NoSelfTraining_PostProcessing\",\n",
    "    # \"n_nst_pp_md\" : \"Naive_NoSelfTraining_PostProcessing_MixedData\",\n",
    "\n",
    "    \"r_nst_npp\" : \"Replay_NoSelfTraining_NoPostProcessing\",\n",
    "    \"r_st_npp\" : \"Replay_SelfTraining_NoPostProcessing\",\n",
    "    \"r_nst_pp\" : \"Replay_NoSelfTraining_PostProcessing\",\n",
    "    # \"r_nst_pp_md\" : \"Replay_NoSelfTraining_PostProcessing_MixedData\",\n",
    "    \n",
    "    \"j_nst_npp\" : \"JointTraining_NoSelfTraining_NoPostProcessing\",\n",
    "    \"j_st_npp\" : \"JointTraining_SelfTraining_NoPostProcessing\",\n",
    "    \"j_nst_pp\" : \"JointTraining_NoSelfTraining_PostProcessing\",\n",
    "    # \"j_nst_pp_md\" : \"JointTraining_NoSelfTraining_PostProcessing_MixedData\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2label = {\n",
    "    \"n_nst_npp\" : \"Naive\",\n",
    "    \"n_st_npp\" : \"Naive_SelfTraining\",\n",
    "    \"n_nst_pp\" : \"Naive_PostProcessing\",\n",
    "    \"n_nst_pp_md\" : \"Naive_PostProcessing_MixedData\",\n",
    "\n",
    "    \"r_nst_npp\" : \"Replay\",\n",
    "    \"r_st_npp\" : \"Replay_SelfTraining\",\n",
    "    \"r_nst_pp\" : \"Replay_PostProcessing\",\n",
    "    \"r_nst_pp_md\" : \"Replay_PostProcessing_MixedData\",\n",
    "    \n",
    "    \"j_nst_npp\" : \"JointTraining\",\n",
    "    \"j_st_npp\" : \"JointTraining_SelfTraining\",\n",
    "    \"j_nst_pp\" : \"JointTraining_PostProcessing\",\n",
    "    \"j_nst_pp_md\" : \"JointTraining_PostProcessing_MixedData\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_accuracy = []\n",
    "running_ece = []\n",
    "final_accuracy = []\n",
    "final_ece = []\n",
    "bins = None\n",
    "ece_hist_vals = []\n",
    "\n",
    "for k, name in run2name.items():\n",
    "    print(f\">> {name} <<\")\n",
    "    with open(f\"{DATA_PATH}/{DATASET}_{MODEL_NAME}_{name}_dict\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "        # print(\"---- ACCURACY ----\")\n",
    "\n",
    "        metric_str = \"Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp\"\n",
    "        m = []\n",
    "        for i in range(len(data)):\n",
    "            cur_exp_dict = data[i]\n",
    "            cur_exp_acc = 0\n",
    "            for j in range(NUM_EXPERIENCES):\n",
    "                # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "                cur_exp_acc += cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            m.append(cur_exp_acc/NUM_EXPERIENCES)\n",
    "        \n",
    "        # duplicate for JointTraining\n",
    "        if len(m) < NUM_EXPERIENCES:\n",
    "            m = m*5\n",
    "        # print(k, m)\n",
    "        running_accuracy.append((k, m))\n",
    "        final_accuracy.append((k, running_accuracy[-1][-1][-1]))\n",
    "\n",
    "        # print(\"---- ECE ----\")\n",
    "\n",
    "        metric_str = \"ECE_Exp/eval_phase/test_stream/Task000/Exp\"\n",
    "        m = []\n",
    "        for i in range(len(data)):\n",
    "            cur_exp_dict = data[i]\n",
    "            cur_exp_ece = 0\n",
    "            for j in range(NUM_EXPERIENCES):\n",
    "                # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"])\n",
    "                cur_exp_ece += cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            m.append(cur_exp_ece/NUM_EXPERIENCES)\n",
    "        \n",
    "        # duplicate for JointTraining\n",
    "        if len(m) < NUM_EXPERIENCES:\n",
    "            m = m*5\n",
    "        # print(k, m)\n",
    "        running_ece.append((k, m))\n",
    "        final_ece.append((k, running_ece[-1][-1][-1]))\n",
    "\n",
    "        # print(\"---- ECE HISTOGRAMS ----\")\n",
    "\n",
    "        metric_str = \"ExpECEHistogram/eval_phase/test_stream/Exp\"\n",
    "        m = []\n",
    "        i = 4 if \"Joint\" not in name else 0\n",
    "        cur_exp_dict = data[i]\n",
    "        for j in range(NUM_EXPERIENCES):\n",
    "            # print(i, j, metric_str + f\"{j:03d}\", cur_exp_dict[metric_str + f\"{j:03d}\"], type(cur_exp_dict[metric_str + f\"{j:03d}\"]))\n",
    "            fig = cur_exp_dict[metric_str + f\"{j:03d}\"]\n",
    "            axes_list = fig.get_axes()\n",
    "            for ax in axes_list:\n",
    "                for line in ax.get_lines()[-1:]:\n",
    "                    x_data = line.get_xdata()\n",
    "                    y_data = line.get_ydata()\n",
    "                    # print({'x': x_data, 'y': y_data})\n",
    "                    if bins is None:\n",
    "                        bins = x_data\n",
    "                    m.append(y_data)\n",
    "        # print(bins, m)\n",
    "        bin_vals = []\n",
    "        for i in range(len(bins)):\n",
    "            x = []\n",
    "            for j in range(len(m)):\n",
    "                # print(j, i, m[j][i])\n",
    "                x.append(m[j][i])\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            bin_vals.append((mean, std))\n",
    "        # print(bins, bin_vals)\n",
    "        ece_hist_vals.append((k, bin_vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 1: Average accuracy on all experiences after training on exp j\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "x_axis = list(range(NUM_EXPERIENCES))\n",
    "for name, vals in running_accuracy:\n",
    "    plt.plot(x_axis, vals, label=run2label[name])\n",
    "plt.title('Average Experience Accuracy')\n",
    "plt.xlabel('#TrainedExperience')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, NUM_EXPERIENCES-1)\n",
    "plt.xticks(x_axis, x_axis)\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 2: Average ece on all experiences after training on exp j\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "x_axis = list(range(NUM_EXPERIENCES))\n",
    "for name, vals in running_ece:\n",
    "    plt.plot(x_axis, vals, label=run2label[name])\n",
    "plt.title('Average Experience ECE')\n",
    "plt.xlabel('#TrainedExperience')\n",
    "plt.ylabel('ECE')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, NUM_EXPERIENCES-1)\n",
    "plt.xticks(x_axis, x_axis)\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE : average accuracy/ece on all experiences at the end of training\n",
    "\n",
    "table_data = []\n",
    "for (n, acc), (_, ece) in zip(final_accuracy, final_ece):\n",
    "    table_data.append((run2label[n], round(acc, 2), round(ece,2)))\n",
    "\n",
    "dt = pd.DataFrame(table_data, columns=[\"RunName\", \"Accuracy\", \"ECE\"])\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM : avg/std across all experiences at the end of training\n",
    "\n",
    "valid_colors = ['green', 'red', 'cyan', 'magenta', 'black', 'purple', 'orange', 'brown', 'gray', 'olive', 'indigo', 'turquoise']\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(12, 8))\n",
    "axs = axs.flatten()\n",
    "for i, (name, vals) in enumerate(ece_hist_vals):\n",
    "    m = [e[0] for e in vals]\n",
    "    l = [e[0] - e[1] for e in vals]\n",
    "    u = [e[0] + e[1] for e in vals]\n",
    "    axs[i].plot([0, 1], [0, 1], '--', label='ideal')\n",
    "    axs[i].plot(bins, m, label=run2label[name], color=valid_colors[i])\n",
    "    axs[i].fill_between(bins, l, u, alpha=0.3, linestyle='--', color=valid_colors[i])\n",
    "    axs[i].legend(loc='upper left', fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
